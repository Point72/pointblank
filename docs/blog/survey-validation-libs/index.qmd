---
jupyter: python3
html-table-processing: none
title: "Validation Libraries for Polars (2025 Edition)"
author: Rich Iannone
date: 2025-06-01
freeze: true
---

Data validation is a very important part of any data pipeline. And with Polars gaining popularity as
a superfast DataFrame library, developers need validation tools that work seamlessly with it. In
this survey (conducted halfway through 2025) we'll explore four Python validation libraries that
support Polars DataFrames. Each one is sufficiently different enough from another, and so they each
bring their own strengths and ideal use cases to the table.

The Python libraries we're covering are:

1. Pandera
2. Patito
3. Pointblank
4. Validoopsie

We'll run through a number of examples with each of the libraries, using this Polars DataFrame as
the table to validate:

```{python}
import polars as pl

# Standard dataset for all validation examples
user_data = pl.DataFrame({
    "user_id": [1, 2, 3, 4, 5],
    "age": [25, 30, 22, 45, 95],  # <- very high age
    "email": [
        "user1@example.com", "user2@example.com", "invalid-email",  # <- an invalid email
        "user4@example.com", "user5@example.com"
    ],
    "score": [85.5, 92.0, 78.3, 88.7, 95.2]
})
```

We'll try to run the same data validation across the surveyed libraries, so we'll check:

- the schema
- that `user_id` values are greater than `0`
- that `age` values are between `18` and `80` (inclusive)
- that `email` strings match to an email-checking regex
- that `score` is between `0` and `100` (again with inclusive bounds)

Now let's begin by looking at Pandera.

## 1. Pandera: Schema-First Validation with Statistical Checks

Pandera is a statistical data validation toolkit designed to provide a flexible and expressive API
for performing data validation on dataframe-like objects. The library centers on schema-first
validation, where you define the expected structure and constraints of your data upfront. You can
enable both runtime validation and static type checking integration. Pandera added Polars support in
version `0.19.0` (early 2024).

### Example

```{python}
import pandera.polars as pa

# Define schema using our standard dataset
schema = pa.DataFrameSchema({
    "user_id": pa.Column(pl.Int64, checks=pa.Check.gt(0)),
    "age": pa.Column(pl.Int64, checks=[pa.Check.ge(18), pa.Check.le(80)]),
    "email": pa.Column(pl.Utf8, checks=pa.Check.str_matches(r"^[^@]+@[^@]+\.[^@]+$")),
    "score": pa.Column(pl.Float64, checks=pa.Check.in_range(0, 100))
})

# Validate the schema
try:
    validated_data = schema.validate(user_data)
    print("Validation successful!")
except pa.errors.SchemaError as e:
    print(f"Validation failed: {e}")
```

## 2. Patito: Pydantic-Style Data Models for DataFrames

Patito brings Pydantic's well-received model-based validation approach to DataFrame validation,
creating a bridge between API data validation and DataFrame processing. The library's primary goal
is to provide a familiar, Pydantic-style interface for defining and validating DataFrame schemas,
making it particularly appealing to developers already using Pydantic in their applications.

Patito launched with Polars support from the beginning (in late 2022). Native Polars integration is
touted as one of its core features, reflecting the growing adoption of Polars in the Python
ecosystem.
## 3. Pointblank: Comprehensive Validation with Beautiful Reports

Pointblank is a comprehensive data validation framework designed to make data quality assessment
both thorough and accessible to stakeholders. Originally inspired by the R package of the same name,
Pointblank's primary mission is to provide validation workflows that generate beautiful, interactive
reports that can be shared with both technical and non-technical team members.

Pointblank launched with Polars support as a core feature from its initial Python release in late
2024, built on top of the Narwhals and Ibis compatibility layers to provide consistent DataFrame
operations across multiple backends including Polars, Pandas, and database connections.

