# 📖 **Pointblank MCP Server User Guide**

## **Getting Started with Data Validation in VS Code & Positron**

This guide shows you how to use the Pointblank MCP server to validate your data through natural conversation in VS Code or Positron IDE. Whether you're a data analyst, engineer, or business user, you'll learn how to leverage powerful validation capabilities through simple chat commands.

---

## **🚀 Quick Start**

Ready to experience data validation through conversation? This quick start gets you up and running in just a few minutes. You'll learn what you need, how to configure everything, and start your first validation conversation.## **🗺️ Roadmap: Making MCP Even Easier**

We're working to make Pointblank's MCP server even more accessible and discoverable. Here's what's coming after the current MCP features are released to PyPI.

### **VS Code Marketplace Integration**

**Leveraging Existing VS Code MCP Features:**
- VS Code already supports browsing MCP servers (@mcp in Extensions view)
- Direct installation links from websites work today
- Auto-discovery from other tools like Claude Desktop is available

**What We're Adding for Pointblank:**
- Submit Pointblank to VS Code's curated MCP server list
- Create web installation links for one-click setup
- Develop marketplace listing materials and documentation

**VS Code Extensions View Integration:**
- Work toward having "Pointblank" appear in VS Code MCP browsing
- Provide clear installation instructions and examples
- Automatic configuration with sensible defaults

### **Enhanced Discovery Experience** Need**

You'll need **VS Code or Positron IDE** with MCP support, **Pointblank** with MCP dependencies (`pip install pointblank[mcp,pd]`), and **data files** in CSV, Excel, Parquet, or JSON format.

### **5-Minute Setup**

1. **Install dependencies**:
   ```bash
   pip install pointblank[mcp,pd,excel]
   ```

2. **Configure VS Code/Positron** to use the MCP server (see [Setup Guide](#setup-guide))

3. **Start chatting**:
   ```
   "Load my sales data and check its quality"
   ```

That's it! You're ready to validate data through conversation.

---

## **🌐 Understanding the MCP Ecosystem**

### **What Makes MCP Different**

The Model Context Protocol (MCP) ecosystem is still evolving, and it works quite differently from traditional software markets like VS Code extensions. Understanding this landscape helps set expectations for setup and discovery.

### **How People Find MCP Servers**

**Emerging Centralized Discovery**:

- VS Code now has a "Browse MCP Servers" feature accessible via Extensions view (@mcp search)
- curated list of MCP servers available through VS Code's Command Palette (`MCP: Browse Servers`)
- direct installation links from websites that can open VS Code and install servers
- auto-discovery from other tools like Claude Desktop

**Traditional Discovery Methods Still Common**:

- GitHub repositories and documentation
- community discussions and blog posts
- package manager listings (PyPI, npm, etc.)
- word of mouth in AI/ML communities

**Current Discovery Methods**:

- **Documentation searches**: finding packages that mention MCP support
- **Community lists**: Awesome MCP lists on GitHub
- **Direct recommendations**: from colleagues or online communities
- **Organic discovery**: finding MCP servers while researching other tools

### **Installation and Configuration Patterns**

**Global Installation Approach**:

```bash
# Install the package globally
pip install pointblank[mcp]  # Available system-wide
# Configure in each IDE/client you use
```

**Project-Specific Approach**:

```bash
# Install in a specific project environment
cd my-data-project
uv add pointblank[mcp]  # Available only in this project
# Configure MCP client to use this environment
```

**Setup Reality**:

- **Manual configuration**: each MCP client (VS Code, Positron, Claude Desktop, etc.) requires separate setup
- **JSON editing**: most configuration involves editing JSON files
- **Environment management**: ensuring correct Python paths and dependencies
- **No auto-discovery**: clients don't automatically find available MCP servers

### **Why This Matters for You**

**Current Challenges**:

- **Discovery friction**: no easy way to browse available MCP servers
- **Setup complexity**: manual configuration for each client
- **Documentation scattered**: setup instructions vary significantly between projects
- **Version compatibility**: no automatic dependency resolution

**Future Improvements**:

The MCP ecosystem is rapidly evolving toward:

- **Centralized discovery**: official or community-maintained registries
- **One-click installation**: IDE plugins that handle setup automatically
- **Better documentation**: standardized setup guides and examples
- **Dependency management**: automatic compatibility checking

**Why Pointblank Stands Out**:

This evolving landscape is exactly why we've invested heavily in clear documentation and examples. Since discovery is challenging, packages with great user guides and compelling use cases (like data validation) tend to get adopted more quickly.

### **Getting the Most from MCP**

**Start Simple**:

- set up one MCP server (like Pointblank) and get comfortable with the workflow
- use it consistently for a specific task before adding more servers
- focus on servers that solve real problems you have

**Build Gradually**:

- add servers that complement each other (data loading + validation + visualization)
- create standard configurations you can reuse across projects
- document your own setup process for team sharing

**Stay Connected**:

- follow MCP development and community discussions
- share your own experiences and configurations
- contribute back to improve the ecosystem

---

## **💬 How to Talk to Pointblank**

The key to effective data validation is knowing how to communicate naturally with the MCP server. This section shows you the essential commands and conversation patterns that make Pointblank understand exactly what you need.

### **Basic Commands**

| What You Want | What You Say | What Happens |
|---------------|--------------|--------------|
| Load data | "Load the file `/path/to/data.csv`" | File gets loaded into memory |
| Check quality | "Analyze the data quality" | Comprehensive data profiling |
| Create rules | "Set up validation for customer data" | Validation plan created |
| Run validation | "Check if the data passes validation" | Rules executed, results shown |
| Fix issues | "Export the problem rows" | Bad data saved for fixing |

### **Natural Language Examples**

**✅ Good (Natural)**:
- "Can you check if my customer emails are valid?"
- "I think there are duplicates in the sales data"
- "Set up validation rules for financial transactions"
- "Export all rows that failed validation"

**❌ Avoid (Too Technical)**:
- "Execute col_vals_regex on email column with pattern validation"
- "Apply interrogate() method to validator instance"
- "Generate validation_set output with step_index parameter"

---

## **📊 Common Use Cases**

Once you understand how to communicate with Pointblank, you'll want to see it in action. These real-world scenarios show how different users leverage the MCP server for their daily data validation needs. Each example includes the full conversation flow and explains the benefits you'll experience.

### **1. Quick Data Quality Check**

**Scenario**: You received a new dataset and want to quickly assess its quality.

```
👤 User: "I just got customer_data.csv. Can you check if it looks good?"

🤖 Assistant: "I'll load and analyze your customer data..."
             [Loads file and runs quality checks]
             "Found 15,847 customers with 8 columns. Data quality:
              - ✅ No duplicate IDs
              - ⚠️ 2% missing phone numbers
              - ❌ 234 invalid email formats
              Would you like me to investigate the email issues?"

👤 User: "Yes, show me what's wrong with the emails"

🤖 Assistant: [Analyzes email patterns]
             "Email issues found:
              - 89 missing @ symbols
              - 145 invalid domains (.comm, .co.uk.uk)
              Should I create validation rules to catch these?"
```

**Key Benefits**:

- get quality assessment in seconds
- understand data issues in plain English
- receive actionable recommendations

### **2. Setting Up Validation Rules**

**Scenario**: You want to establish consistent validation for recurring data loads.

```
👤 User: "Set up validation rules for our daily sales reports"

🤖 Assistant: "I'll create a validation template for sales data. What should I check for?"

👤 User: "Make sure amounts are positive, dates are valid, and customer IDs exist"

🤖 Assistant: [Creates validator with rules]
             "✅ Sales validation template created:
              1. Amount > 0
              2. Valid transaction dates
              3. Customer ID not null
              4. Customer ID follows ID pattern
              Should I test these rules on your current data?"

👤 User: "Yes, and save this template for daily use"

🤖 Assistant: [Runs validation and saves template]
             "✅ Validation passed! Template saved as 'daily_sales_validation'
              For future files, just say: 'run daily sales validation'"
```

**Key Benefits**:

- reusable validation templates
- consistent quality standards
- automated daily checks

### **3. Investigating Data Issues**

**Scenario**: Your dashboard shows suspicious numbers and you need to investigate.

```
👤 User: "Our conversion rates jumped to 95% this week. Something's wrong"

🤖 Assistant: "That does sound suspicious! Let me analyze your conversion data.
             What file should I examine?"

👤 User: "weekly_metrics.xlsx, especially the marketing tab"

🤖 Assistant: [Loads and analyzes data]
             "🚨 Found the issue! Test data contamination:
              - 1,247 test emails (@test.com, @example.org)
              - These have 100% conversion rates
              - Real conversion rate is 4.2% (normal)
              Should I filter out test data and recalculate?"

👤 User: "Yes! And prevent this from happening again"

🤖 Assistant: [Cleans data and creates validation]
             "✅ Clean metrics: 4.2% conversion rate
              ✅ Added test data detection to prevent future issues
              ✅ Saved clean data to weekly_metrics_clean.xlsx"
```

**Key Benefits**:

- rapid issue diagnosis
- root cause identification
- automated prevention for future

### **4. Preparing Data for Important Use**

**Scenario**: You need bulletproof data for a board presentation, publication, or audit.

```
👤 User: "I'm presenting to investors next week. Need to validate our growth metrics"

🤖 Assistant: "Investor presentations require institutional-grade data quality!
             What metrics files should I validate?"

👤 User: "user_growth.csv, revenue_cohorts.csv, and retention_metrics.csv"

🤖 Assistant: [Comprehensive validation across files]
             "📊 Investor-Grade Validation Complete:

              ✅ Data Integrity: All metrics cross-validate
              ✅ Growth Rates: Realistic and explainable
              ✅ Cohort Math: Revenue retention calculations correct
              ⚠️ Flagged: 3 months show >100% growth (need explanation)

              🎯 Investor Talking Points:
              - 34% monthly growth (top quartile SaaS)
              - 118% net revenue retention (best-in-class)
              - Strong organic growth with viral coefficient 1.3x

              Documentation package ready for due diligence!"

👤 User: "Perfect! The high growth months were our viral campaigns"

🤖 Assistant: "✅ Validated campaign correlation with growth spikes
              ✅ Generated investor data quality documentation
              You're ready for investor meetings! 🚀"
```

**Key Benefits**:

- institutional-quality validation
- stakeholder-ready documentation
- confidence in high-stakes presentations

These examples show the breadth of validation scenarios Pointblank can handle. From quick data checks to complex multi-dataset validation, the natural language interface adapts to your needs and expertise level.

---

## **🔧 Advanced Features**

Beyond basic validation, Pointblank's MCP server offers sophisticated capabilities for power users and complex data scenarios. These features help you build comprehensive data quality workflows that scale with your organization's needs.

### **Data Profiling & Insights**

Ask for comprehensive analysis:

```
"Profile my dataset and suggest validation rules"
"What data quality issues should I be worried about?"
"Analyze correlations and detect anomalies"
```

**Example Output**:

```
📊 Data Profile Summary:
- 50,000 rows, 12 columns
- 3 data quality issues detected
- 8 validation rules suggested
- 2 strong correlations found

🔍 Suggested Validations:
1. Email format validation (234 invalid found)
2. Age range check (5 outliers >120 years)
3. Unique ID constraint (23 duplicates found)
```

### **Validation Templates**

Use pre-built templates for common scenarios:

```
"Apply financial data validation template"
"Use customer data validation rules"
"Set up survey data quality checks"
```

**Available Templates**:

- **financial_data**: transaction amounts, dates, account IDs
- **customer_data**: emails, phone numbers, demographics
- **survey_data**: response completeness, scale validation
- **sensor_data**: timestamp continuity, value ranges

### **Cross-Dataset Validation**

Validate relationships between multiple files:

```
"Check that customer IDs match between sales and customer files"
"Validate transaction dates align across all data sources"
"Ensure user journey data is consistent across web and mobile"
```

### **Automated Workflows**

Set up recurring validation:

```
"Create daily validation for our ETL pipeline"
"Set up automated quality checks for incoming data"
"Monitor data freshness and completeness"
```

These advanced features transform Pointblank from a simple validation tool into a comprehensive data quality platform. The natural language interface makes even complex workflows accessible to team members with varying technical backgrounds.

---

## **⚙️ Setup Guide**

Ready to get started? This section walks you through the complete installation and configuration process. We'll cover everything from basic installation to advanced configuration options for different environments.

### **Installation**

1. **Install Pointblank with MCP support**:

   **Recommended for most users**:
   ```bash
   pip install pointblank[mcp,pd,excel]
   ```

   **What the optional dependencies provide**:
   - `mcp` - Model Context Protocol server functionality (required)
   - `pd` - pandas backend for data processing
   - `pl` - polars backend for faster processing of large datasets
   - `excel` - Excel file support via openpyxl

   **Other installation options**:
   ```bash
   # Minimal MCP server only
   pip install pointblank[mcp]

   # With both pandas and polars backends
   pip install pointblank[mcp,pd,pl]

   # Complete installation with all features
   pip install pointblank[mcp,pd,pl,excel]
   ```

2. **Alternative with uv (recommended for Python project management)**:

   ```bash
   uv add pointblank[mcp,pd,excel]
   ```

### **VS Code & Positron Configuration**

**For VS Code**: VS Code offers multiple ways to configure MCP servers, each suited for different use cases.

> ⚠️ **Security Warning**: MCP servers can run arbitrary code on your machine. Only add servers from trusted sources, and review the configuration before starting. VS Code will prompt you to confirm trust when you start an MCP server for the first time.

**Option 1: Workspace Configuration (Recommended for Teams)**

Best for sharing configuration with team members and project-specific setups.

1. Create a `.vscode/mcp.json` file in your workspace root
2. Add this configuration:
```json
{
  "servers": {
    "pointblank": {
      "command": "python",
      "args": ["-m", "pointblank_mcp_server.pointblank_server"]
    }
  }
}
```

**Option 2: User Configuration (Personal Use)**

Best for personal use across all your workspaces.

1. run `MCP: Open User Configuration` from Command Palette (⌘/Ctrl + Shift + P)
2. add the same JSON configuration as above
3. the server will be available in all your workspaces

**Option 3: Command Palette Setup**

Quick interactive setup option.

1. run `MCP: Add Server` from Command Palette
2. choose server type and provide information
3. select "Workspace Settings" or "Global" based on your needs

**Option 4: Auto-Discovery**

VS Code can automatically detect MCP servers from other tools like Claude Desktop.

1. enable with setting: `chat.mcp.discovery.enabled`
2. VS Code will discover and reuse existing MCP configurations

**For Positron IDE**:

1. open Positron Settings
2. navigate to Extensions → MCP Server Configuration
3. add configuration (format may vary from VS Code)

4. **Test the connection**:
   ```
   "Are you connected to Pointblank?"
   ```

5. **Start validating**:
   ```
   "Load my test data and show me what you can do"
   ```

**Managing MCP Servers in VS Code**:

- view installed servers: `MCP: Show Installed Servers` or check Extensions view
- list all servers: `MCP: List Servers`
- reset cached tools: `MCP: Reset Cached Tools` (if server capabilities change)

> **💡 Positron Note**: Positron IDE is particularly well-suited for data validation workflows as it combines VS Code's extensibility with RStudio-inspired data science features. Its built-in data viewer and variable explorer work seamlessly with Pointblank's validation results.

### **File Support**

| Format | Extension | Backend | Notes |
|--------|-----------|---------|-------|
| CSV | `.csv` | pandas, polars | Universal support |
| Excel | `.xlsx`, `.xls` | pandas | Requires openpyxl |
| Parquet | `.parquet` | pandas, polars | High performance |
| JSON | `.json` | pandas, polars | Structured data |
| JSONL | `.jsonl` | pandas, polars | Line-delimited JSON |

With your MCP server properly configured, you'll be able to load and validate data from any of these formats using simple conversational commands. The setup process might seem complex initially, but once configured, the natural language interface makes data validation incredibly intuitive.

---

## **🎯 Best Practices**

To get the most out of your Pointblank MCP server, follow these proven practices. They'll help you communicate more effectively, build better validation workflows, and maintain high data quality standards across your organization.

### **Effective Communication**

**✅ Do**:

- be specific about your concerns: "Check for duplicate customer IDs"
- provide context: "This is for a board presentation"
- ask for explanations: "Why did validation fail?"
- request actionable steps: "How do I fix these issues?"

**❌ Don't**:

- use technical function names: "Run col_vals_not_null"
- assume AI knows your business: Explain what data represents
- skip validation on important data: Always verify before decisions

### **Workflow Optimization**

1. **Start with profiling**: "analyze my data" before creating rules
2. **Build incrementally**: add validation rules one at a time
3. **Save templates**: reuse validation patterns for similar data
4. **Document decisions**: ask for validation summaries and reports

### **Data Quality Strategy**

1. **Prevention over correction**: set up validation for incoming data
2. **Continuous monitoring**: regular quality checks on recurring data
3. **Business alignment**: validation rules should match business requirements
4. **Stakeholder communication**: use AI-generated summaries for reporting

These practices ensure you're not just validating data, but building a sustainable data quality culture that scales with your organization's growth.

---

## **🔍 Troubleshooting**

Even with the best setup, you might encounter issues. This section covers the most common problems and their solutions, helping you quickly resolve any difficulties and get back to productive data validation.

### **Common Issues**

| Problem | Symptoms | Solution |
|---------|----------|----------|
| File not loading | "File not found" error | Check file path, use absolute paths |
| Validation failing unexpectedly | All rules fail | Check data types and column names |
| Slow performance | Long processing times | Use sampling for large datasets |
| Memory issues | Process crashes | Load data in chunks or use polars backend |

### **Getting Help**

**Ask the AI for help**:

```
"I'm getting validation errors I don't understand"
"The data looks wrong but I'm not sure why"
"How do I validate financial transaction data?"
"What's the best way to check email addresses?"
```

**Error Diagnosis**:

```
"Explain why my validation failed"
"Show me examples of the data that failed validation"
"What's causing the data quality issues?"
```

**Performance Optimization**:

```
"This is taking too long. Can you optimize?"
"Use a sample of the data for testing"
"Switch to a faster backend for this large file"
```

---

## **📈 Success Metrics**

How do you know your Pointblank implementation is working well? This section helps you measure the effectiveness of your data validation workflows and understand the business impact you're achieving.

### **How to Know It's Working**

**✅ Quality Indicators**:

- validation catches real issues in your data
- false positives are rare and explainable
- business stakeholders trust your data quality
- data-driven decisions are made with confidence

**📊 Efficiency Gains**:

- faster data quality assessment (minutes vs hours)
- reduced manual Excel checking and SQL queries
- consistent validation across team members
- automated quality gates prevent bad data propagation

**🎯 Business Impact**:

- fewer data-driven mistakes and corrections
- increased confidence in reporting and analysis
- better stakeholder trust in data products
- reduced time spent on data quality firefighting

The combination of natural language interaction with enterprise-grade validation creates a powerful platform that grows with your data quality needs. Whether you're handling simple CSV files or complex multi-source validation workflows, Pointblank's MCP server provides the flexibility and power you need.

---

## **🚀 Advanced Usage**

For users ready to push beyond basic validation, these advanced patterns show how to integrate Pointblank into sophisticated data workflows. These examples demonstrate enterprise-level automation and complex validation scenarios.

### **Integration with Data Pipelines**

```bash
# CI/CD validation script
#!/bin/bash
echo "Validating daily ETL output..."
python -c "
# Chat with Pointblank MCP server
validate_daily_data('/data/daily_output.csv')
"
exit_code=$?
if [ $exit_code -eq 0 ]; then
    echo "✅ Data quality validation passed"
    deploy_to_production()
else
    echo "❌ Data quality issues found: blocking deployment"
    exit 1
fi
```

### **Custom Validation Rules**

```
"Create validation that checks our business rules:
- customer lifetime value must be positive
- order amounts match sum of line items
- subscription dates don't overlap for same customer
- geographic data is consistent (city matches state)"
```

### **Multi-Source Validation**

```
"I have user data from three sources: web app, mobile app, and customer service.
Check that:
- user IDs are consistent across all sources
- no user appears in mobile without appearing in web first
- customer service interactions have matching user records"
```

These advanced patterns demonstrate how Pointblank scales from individual data analysis to enterprise data infrastructure. The natural language interface remains simple even as validation complexity increases.

---

## **�️ Roadmap: Making MCP Even Easier**

We're working to make Pointblank's MCP server even more accessible and discoverable. Here's what's coming:

### **VS Code Marketplace Integration**

**One-Click Installation from Web**:

- direct installation links on websites and documentation
- browse and install from curated MCP server lists
- no more manual JSON configuration for basic setups

**VS Code Extensions View**:

- search for "Pointblank" in VS Code Extensions marketplace
- install with a single click, just like regular extensions
- automatic configuration with sensible defaults

### **Simplified Discovery**

**MCP Server Registry**:

- Pointblank listed in official MCP server catalogs
- searchable by data validation, data quality, Python tags
- user ratings and usage statistics

**Auto-Discovery Enhancements**:

- automatic detection when Pointblank is installed in environment
- smart suggestions based on project files (CSV, Excel, etc.)
- integration with existing data science workflows

### **Enhanced Installation Experience**

**Installation Wizard**:

- guided setup for first-time users
- automatic dependency detection and recommendations
- environment-specific configuration (conda, venv, etc.)

**Pre-configured Templates**:

- ready-to-use workspace configurations for common data science setups
- integration with popular data science Docker images
- dev container templates with Pointblank pre-configured

### **Developer Experience Improvements**

**Live Configuration Validation**:

- real-time feedback on MCP server configuration
- helpful error messages and troubleshooting suggestions
- configuration health checks and recommendations

**Enhanced IDE Integration**:

- syntax highlighting for validation rules in chat
- autocomplete for common validation patterns
- inline documentation and examples

### **How You Can Help**

**Early Adoption**:

- try the current MCP features and provide feedback
- share your use cases and configuration challenges
- contribute to documentation and examples

**Community Building**:

- star the GitHub repository to boost discoverability
- share success stories and tutorials
- report issues and suggest improvements

**Enterprise Feedback**:

- share your organization's MCP deployment needs
- provide feedback on security and compliance requirements
- suggest integration points with existing data infrastructure

> **💡 Stay Updated**: Follow the [GitHub repository](https://github.com/posit-dev/pointblank) for roadmap updates and release announcements. Your feedback directly influences development priorities!

---

## **�📚 Additional Resources**

Ready to dive deeper? These resources provide comprehensive reference materials, examples, and community support to help you master Pointblank's MCP server capabilities.

### **Documentation**
- [MCP Server API Reference](README_MCP.md)
- [VS Code Chat Scenarios](VS_CODE_CHAT_SCENARIOS.md)
- [Testing Guide](MCP_TESTING_GUIDE.md)

### **Examples**
- [Demo Scripts](demo_*.py)
- [Sample Datasets](data_raw/)
- [Validation Templates](pointblank_mcp_server/)

### **Community**
- [GitHub Repository](https://github.com/posit-dev/pointblank)
- [Issue Tracker](https://github.com/posit-dev/pointblank/issues)

With these resources, you have everything needed to become proficient with Pointblank's natural language data validation. The combination of comprehensive documentation, practical examples, and active community support ensures you can tackle any data quality challenge with confidence.
- [Discussions](https://github.com/posit-dev/pointblank/discussions)

---

**🎉 You're Ready!** Start validating your data through conversation and experience the power of AI-assisted data quality management in VS Code!

Remember: The best validation strategy is the one you actually use. Start simple, build confidence, and gradually incorporate more sophisticated checks as you become comfortable with the conversational interface.
