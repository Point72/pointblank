---
title: Data Inspection and Exploration
jupyter: python3
toc-expand: 2
---

Pointblank’s CLI (`pb`) makes it easy to view your data before running validations. It has several
commands that are exceedingly useful for understanding your data’s structure, checking for obvious
issues, and confirming that your data source is being read correctly. We also make it easy to
explore data in various formats and locations. Let's go through each of the commands for inspecting
and exploring data.

:::

## `pb info`: Inspecting Data Structure

Use `pb info` to display basic information about your data source. Here's how this works with a
local CSV file:

![](/assets/pb-info-worldcities-csv.png){width=100%}

This command shows the (1) table type (e.g., `pandas`, `polars`, etc.), (2) the number of rows and
columns, and (3) the data source path or identifier.

That example used a local CSV file. The same file is also present in Pointblank's GitHub repository
(in the `data-raw` directory) and the CLI is able to load the data from there as well:

![](/assets/pb-info-worldcities-github-csv.png){width=100%}

The `pb info` command is useful before running validations to confirm your data source's dimensions,
and, whether it can even be loaded.

::: {.callout-info}

You can inspect a wide variety of data sources using the CLI! Here are some examples with `pb info`:

```bash
pb info small_table         # built in dataset
pb info worldcities.csv     # single CSV file
pb info meteo.parquet       # single Parquet file
pb info "*.parquet"         # several Parquet files
pb info "data/*.parquet"    # partitioned Parquet files
pb info "duckdb:///warehouse/analytics.ddb::customer_metrics" # DB table via connection string
pb info https://github.com/posit-dev/pointblank/blob/main/data_raw/global_sales.csv # GitHub URL
```

And these input schemes work with all other commands that accept a `DATA_SOURCE`.
:::


## `pb preview`: Previewing Data

Use `pb preview` to view the first and last rows of your data. Let's try it out with the
`worldcities.csv` file:

![](/assets/pb-preview-worldcities-csv.png){width=100%}


Here are some useful options:

- `--rows N`: show N rows from the top, default: 5
- `--columns "col1,col2"`: show only specified columns
- `--col-range "1:10"`: show columns by position
- `--col-first N`: show first N columns
- `--col-last N`: show last N columns
- `--no-row-numbers`: hide row numbers
- `--output-html file.html`: save preview as an HTML file

Here's an example where only the `name`, `age`, and `email` columns from `data.csv` are shown (and
we limit this to the top 10 rows):

```bash
pb preview data.csv --columns "name,age,email" --rows 10
```

## `pb scan`: Column Summary and Profiling

Use `pb scan` for a comprehensive column summary, including:

- data types
- missing value counts
- unique value counts
- summary statistics (mean, standard deviation, min, max, quartiles)

```bash
pb scan data.csv
pb scan "data/*.parquet"
pb scan "duckdb:///warehouse/analytics.ddb::customer_metrics"
pb scan small_table
```

Here are the options:

- `--columns "col1,col2"` (scan only specified columns)
- `--output-html file.html` (save scan as HTML report)

## `pb missing`: Missing Value Patterns

Use `pb missing` to generate a missing values report, visualizing missingness across columns and row
sectors:

```bash
pb missing data.csv
pb missing "data/*.parquet"
pb missing "duckdb:///warehouse/analytics.ddb::customer_metrics"
pb missing small_table
```

There's an option here as well:

- `--output-html file.html` (save missing values report as HTML)

## Some Useful Tips on When and How to Use

- use `pb info` and before running validations to confirm your data source can be loaded.
- use `pb preview` to quickly understand what the data looks like.
- use `pb missing` to visualize and diagnose missing data patterns.
- use `pb scan` for a quick data profile and to spot outliers or data quality issues.
