---
title: Data Inspection and Exploration
jupyter: python3
toc-expand: 2
---

Pointblank’s CLI (`pb`) makes it easy to view your data before running validations. It has several
commands that are exceedingly useful for understanding your data’s structure, checking for obvious
issues, and confirming that your data source is being read correctly. We also make it easy to
explore data in various formats and locations. Let's go through each of the commands for inspecting
and exploring data.

## `pb info`: Inspecting Data Structure

Use `pb info` to display basic information about your data source. Here's how this works with a
local CSV file:

![](/assets/pb-info-worldcities-csv.png){width=100%}

This command shows the (1) table type (e.g., `pandas`, `polars`, etc.), (2) the number of rows and
columns, and (3) the data source path or identifier.

That example used a local CSV file. The same file is also present in Pointblank's GitHub repository
(in the `data-raw` directory) and the CLI is able to load the data from there as well:

![](/assets/pb-info-worldcities-github-csv.png){width=100%}

The `pb info` command is useful before running validations to confirm your data source's dimensions,
and, whether it can even be loaded.

::: {.callout-info}

You can inspect a wide variety of data sources using the CLI! Here are some examples with `pb info`:

```bash
pb info small_table         # built in dataset
pb info worldcities.csv     # single CSV file
pb info meteo.parquet       # single Parquet file
pb info "*.parquet"         # several Parquet files
pb info "data/*.parquet"    # partitioned Parquet files
pb info "duckdb:///warehouse/analytics.ddb::customer_metrics" # DB table via connection string
pb info https://github.com/posit-dev/pointblank/blob/main/data_raw/global_sales.csv # GitHub URL
```

And these input schemes work with all other commands that accept a `DATA_SOURCE`.
:::

## `pb preview`: Previewing Data

Use `pb preview` to view the first and last rows of your data. Let's try it out with the
`worldcities.csv` file:

![](/assets/pb-preview-worldcities-csv.png){width=100%}

As can be seen, `pb preview` gives you a preview of the dataset as a table in the console. The
dataset has 41K rows but we're electing to show only five rows from the head and from the tail.

Let's go over some features of the table preview. First off, the table header provides information
on the data source and the DataFrame library that handled the reading of the CSV. Below the column
names are simplified representations of the data types (e.g., `<obj>` for object, `<f64>` for
Float64). We provide row numbers (in gray) in the table stub to indicate the which of the rows are
from the head or the tail (and a divider helps to distinguish these row groups). If you'd prefer
to eliminate the row numbers, use the `--no-row-numbers` option:

![](/assets/pb-preview-worldcities-csv-no-row-numbers.png){width=100%}

While `pb preview` keeps the row count down, the number of columns shown can be more than you might
need. There are several ways to subset the preview table's columns and a good one (provided you
know the column names) is to use the `--columns` option:

![](/assets/pb-preview-worldcities-csv-column-names.png){width=100%}

You may want to view ranges of columns by index. This is convenient when you want to get a closer
look at a few side-by-side columns and you don't want to bother with getting the set of column names
exactly right. For this, we use the `--col-range` option:

![](/assets/pb-preview-worldcities-csv-column-range.png){width=100%}

And there are many more options that allow for quick iteration while previewing a table. Use
`pb preview --help` to get a helpful listing.

## `pb scan`: Column Summary and Profiling

We can use `pb scan` for fairly comprehensive summaries of column data, including:

- data types
- missing value counts
- unique value counts
- summary statistics (mean, standard deviation, min, max, quartiles, and the interquartile range)

Let's use this on the `worldcities.csv` dataset:

![](/assets/pb-preview-worldcities-csv.png){width=100%}

Each row in the summary table represents a column in the input dataset. Just as in `pb preview` we
get simplified dtypes (in the `Type` column). The `NA` and `UQ` indicate how many missing and unique
values are in the column. The remaining columns are statistical measures and there's an important
thing to note here: the values provided for any string-based columns (here, `city_name` and
`country`) are derived from string lengths.

There are two options for `pb scan`:

- `--columns "col1,col2"` (scan only specified columns)
- `--output-html file.html` (save scan as HTML report)

## `pb missing`: Missing Value Patterns

Use `pb missing` to generate a missing values report, visualizing missingness across columns and row
sectors:

```bash
pb missing data.csv
pb missing "data/*.parquet"
pb missing "duckdb:///warehouse/analytics.ddb::customer_metrics"
pb missing small_table
```

There's an option here as well:

- `--output-html file.html` (save missing values report as HTML)

## Some Useful Tips on When and How to Use

- use `pb info` and before running validations to confirm your data source can be loaded.
- use `pb preview` to quickly understand what the data looks like.
- use `pb missing` to visualize and diagnose missing data patterns.
- use `pb scan` for a quick data profile and to spot outliers or data quality issues.
