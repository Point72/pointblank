---
title: Introduction
jupyter: python3
toc-expand: 2
html-table-processing: none
---
```{python}
#| echo: false
#| output: false
import pointblank as pb
pb.config(report_incl_footer=False)
```

The Pointblank library is all about assessing the state of data quality for a table. You provide the
validation rules and the library will dutifully interrogate the data and provide useful reporting.
We can use different types of tables like Polars and Pandas DataFrames, Parquet files, or various
database tables. Let's walk through what data validation looks like in Pointblank.

## A Simple Validation Table

This is a validation report table that is produced from a validation of a Polars DataFrame:

```{python}
# | code-fold: true

import pointblank as pb

validation = (
    pb.Validate(data=pb.load_dataset(dataset="small_table"), label="Example Validation")
    .col_vals_lt(columns="a", value=10)
    .col_vals_between(columns="d", left=0, right=5000)
    .col_vals_in_set(columns="f", set=["low", "mid", "high"])
    .col_vals_regex(columns="b", pattern=r"^[0-9]-[a-z]{3}-[0-9]{3}$")
    .interrogate()
)

validation
```

Each row in this reporting table constitutes a single validation step. Roughly, the left-hand side
outlines the validation rules and the right-hand side provides the results of each validation step.
While simple in principle, there's a lot of useful information packed into this validation table.

Here's a diagram that describes a few of the important parts of the validation table:

![](/assets/validation-table-diagram.png){width=100%}

There are three things that should be noted here:

- validation steps: each step is a separate test on the table, focused on a certain aspect of the
table
- validation rules: the validation type is provided here along with key constraints
- validation results: interrogation results are provided here, with a breakdown of test units
(*total*, *passing*, and *failing*), threshold flags, and more

The intent is to provide the key information in one place, and have it be interpretable by data
stakeholders.

## Example Code, Step-by-Step

Here's the code that performs the validation on the Polars table.

```python
import pointblank as pb

validation = (
    pb.Validate(data=pb.load_dataset(dataset="small_table"))
    .col_vals_lt(columns="a", value=10)
    .col_vals_between(columns="d", left=0, right=5000)
    .col_vals_in_set(columns="f", set=["low", "mid", "high"])
    .col_vals_regex(columns="b", pattern=r"^[0-9]-[a-z]{3}-[0-9]{3}$")
    .interrogate()
)

validation
```

Note these three key pieces in the code:

- the `Validate(data=)` argument takes a DataFrame or database table that you want to validate
- the methods starting with `col_vals_` specify validation steps that run on specific columns
- the [`interrogate()`](https://posit-dev.github.io/pointblank/reference/Validate.interrogate.html)
method executes the validation plan on the table

This common pattern is used in a validation workflow, where
[`Validate`](https://posit-dev.github.io/pointblank/reference/Validate.html) and
[`interrogate()`](https://posit-dev.github.io/pointblank/reference/Validate.interrogate.html)
bookend a validation plan generated through calling validation methods. And that's data validation
with Pointblank in a nutshell! In the next section we'll go a bit further by understanding how we
can measure data quality with test units and failure thresholds.

## Understanding Test Units

Each validation step will execute a type of validation test on the target table. For example, a
[`col_vals_lt()`](https://posit-dev.github.io/pointblank/reference/Validate.col_vals_lt.html)
validation step can test that each value in a column is less than a specified number. The key
finding that's reported as a result of this test is the number of test units that pass or fail.

Test units are dependent on the test being run. The collection of `col_vals_*` validation methods
will test each and every value in a particular column, so each value will be a test unit (and the
number of test units is the number of rows in the target table). Some validation methods like
[`col_exists()`](https://posit-dev.github.io/pointblank/reference/Validate.col_exists.html) or
[`row_count_match()`](https://posit-dev.github.io/pointblank/reference/Validate.row_count_match.html)
have only a single test unit since they aren't testing individual values but rather if the overall
test passes or fails.

## Using Threshold Levels

Knowing about the numbers of test units across validation methods matters because you have the
option to set thresholds (that can signal 'warning', 'error', and 'critical' flags) based on either
the relative proportion or absolute number of failing test units.

Understanding test units is essential because they form the foundation of Pointblank's threshold
system. With test units defined, you can establish meaningful quality thresholds that trigger
'warning', 'error', or 'critical' signals when data problems arise. These thresholds can be set as
either absolute counts (e.g., 'flag if 5 values fail') or relative proportions (e.g., 'flag if more
than 1% of values fail'), giving you flexible control over data quality monitoring.

Here's a simple example that uses a single validation step along with thresholds set in the
`thresholds=` argument of the validation method.

```{python}
validation_2 = (
    pb.Validate(data=pb.load_dataset(dataset="small_table"))
    .col_vals_lt(columns="a", value=7, thresholds=(2, 4))
    .interrogate()
)

validation_2
```

The code uses `thresholds=(2, 4)` to set a 'warning' threshold of `2` and an `error` threshold of
`4`. If you look at the validation report table, we can see:

- the `FAIL` column shows that 2 tests units have failed
- the `W` column (short for 'warning') shows a filled gray circle indicating those failing test
units reached that threshold value
- the `E` column (short for 'error') shows an open yellow circle indicating that the number of
failing test units is below that threshold

The one final threshold level, `C` (for 'critical'), wasn't set so it appears on the validation
table as a long dash.

Setting thresholds is important since you might want some sort of signal for the discovery of errors
in your data. How you set the particular threshold levels is highly dependent on your tolerance for
data failures. The idea of thresholds and associated actions is central to how Pointblank works, so,
the next two sections in the **User Guide** will deal with (1) a more in-depth treatment of
thresholds, and (2) how to set actions for threshold exceedances.

## Setting Thresholds for Data Quality Signals

Thresholds by themselves are useful for highlighting issues in your data, but Pointblank becomes
even more powerful when you combine thresholds with actions. Actions let you trigger responses when
validation failures exceed threshold levels.

Here's a simple example that adds an action to the previous validation:

```{python}
validation_3 = (
    pb.Validate(data=pb.load_dataset(dataset="small_table"))
    .col_vals_lt(
        columns="a",
        value=7,
        thresholds=pb.Thresholds(warning=2, error=4),
        actions=pb.Actions(
            warning="WARNING: Column 'a' has values that aren't less than 7."
        )
    )
    .interrogate()
)

validation_3
```

In this example:

1. We set a 'warning' threshold of 2 failing test units
2. We add an action using `actions=pb.Actions(warning="...")` that triggers when the 'warning'
threshold is exceeded
3. The action outputs a message to the console when the validation is performed

When we run this code, the warning message `"WARNING: Column 'a' has values that aren't less than
7."` appears in the output. This happens because the validation detected exactly 2 failing values,
which matches our warning threshold. The warning indicator in the report (filled gray circle)
visually confirms this threshold was reached, while the action provides immediate feedback during
the validation process.

Actions make your validation workflows more responsive and integrated with your data pipelines.
Rather than just generating reports, Pointblank can actively notify you of issues through console
messages, Slack notifications, etc.. This combination of thresholds and actions transforms
Pointblank from a passive validation tool into an active component of your data quality management
system.

## Navigating the User Guide

This introduction has covered the basics of data validation with Pointblank. As you continue to
explore the library's capabilities, the User Guide is organized into three main sections:

### Validation Plan

The *Validation Plan* section covers everything you need to know about creating robust
validation plans:

- [Validation Types](types.qmd): Learn about the different validation methods available
- [Column Selection](columns.qmd): Techniques for targeting specific columns
- [Thresholds](thresholds.qmd): Set quality standards and trigger severity levels
- [Actions](actions.qmd): Respond to threshold exceedances with notifications or custom functions
- [Preprocessing](preprocessing.qmd): Transform data before validation
- [Segmentation](segmentation.qmd): Apply validations to specific segments of your data
- [Brief Notes](briefs.qmd): Add context to validation steps

### Post Interrogation

After validating your data, the *Post Interrogation* section helps you analyze and respond to
results:

- [Step Reports](step-reports.qmd): View detailed results for individual validation steps
- [Data Extracts](extracts.qmd): Extract and analyze failing data
- [Sundering Validated Data](sundering.qmd): Split data based on validation results

### Data Inspection

The *Data Inspection* section provides tools to explore and understand your data:

- [Previewing Data](preview.qmd): View samples of your data
- [Column Summaries](col-summary-tbl.qmd): Get statistical summaries of your data
- [Missing Values Reporting](missing-vals-tbl.qmd): Identify and visualize missing data

By following this guide, you'll gain a comprehensive understanding of how to validate, monitor, and
maintain high-quality data with Pointblank.
